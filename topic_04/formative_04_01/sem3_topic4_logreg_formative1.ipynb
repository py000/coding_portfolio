{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0-markdown",
   "metadata": {},
   "source": [
    "# Semester 3 Coding Portfolio Topic 4 Formative Part 1/2:\n",
    "# Logistic Regression\n",
    "\n",
    "This notebook covers the following topics:\n",
    " - logistic regression\n",
    "\n",
    "This notebook is expected to take around 5 hours to complete:\n",
    " - 2 hours for the formative part\n",
    " - 3 hours of self-study on the topics covered by this notebook\n",
    "\n",
    "Like all topics in this portfolio, this topic is split into two sections:\n",
    " - Formative \n",
    " - Summative\n",
    "\n",
    "<b>Formative section</b><br>\n",
    "Simply complete the given functions such that they pass the automated tests. This part is graded Pass/Fail; you must get 100% correct!\n",
    "You can submit your notebook through Canvas as often as you like. Make sure to start doing so early to insure that your code passes all tests!\n",
    "You may ask for help from fellow students and TAs on this section, and solutions might be provided later on.\n",
    "\n",
    "<b>Summative section</b><br>\n",
    "In this section, you are asked to do original work with little guidance, based on the skills you learned in the formative part (as well as lectures and workshops).\n",
    "This section is graded not just on passing automated tests, but also on quality, originality, and effort (see assessment criteria in the assignment description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Please enter your student number here\n",
    "STUDENT_NUMBER = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2-markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "In this exercise, we will use your newly discovered classification skills to classify whether a couple is likely to have a successful relationship based on their astrological signs.\n",
    "In this fictional data set, astrological signs do affect compatibility in some ways which you will have to discover. The effects of astrological signs which we have generated for this exercise may differ from real life, in that there are any.\n",
    "\n",
    "Classification is supervised learning, which means that we already know the outcome for some data, and use this data to train a model to classify unknown data.\n",
    "So, in our capacity as spiritual match-makers, we have compiled a list of relationships to train our classifier with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4-markdown",
   "metadata": {},
   "source": [
    "# Exercise 1A\n",
    "We have two .csv files with data:\n",
    " - Couples: sem3_topic4_logreg_formative1_data1, and\n",
    " - Persons: sem3_topic4_logreg_formative1_data2\n",
    "\n",
    "The couples csv contains the outcome we'd like to predict, but no useful variables to base our prediction on. It only tells us the id of the two partners.\n",
    "It's best if we have both X and Y in a single dataframe before we proceed.\n",
    "Create a dataframe called 'data' with the columns: couple_id, person_a, person_b, outcome, sign_a, sign_b, with the respective signs of persons a and b for each couple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "couples = pd.read_csv('sem3_topic4_logreg_formative1_data1.csv')\n",
    "persons = pd.read_csv('sem3_topic4_logreg_formative1_data2.csv')\n",
    "\n",
    "#. Your solution here ...\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6-markdown",
   "metadata": {},
   "source": [
    "Let's now have a look at the possible outcome variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the outcomes\n",
    "sns.countplot(data=couples, x='outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8-markdown",
   "metadata": {},
   "source": [
    "# Exercise 1B\n",
    "As we can see, one possible outcome for couples is marriage. Although we can train a classifier to classify multiple outcome labels, let's keep it simple for now: We will simply classify whether a couple will be married or not. For this purpose, let's create a one-hot encoding: Create a column for data called 'married' which is equal to 1 if the couple is married and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. Your solution here ...\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10-markdown",
   "metadata": {},
   "source": [
    "# Exercise 1C\n",
    "Now we need to do the same to X: our input features. Since we have two categorical variables (sign_a and sign_b) with 12 possible values each, let's use sklearn's OneHotEncoder class to create vectors instead of manually creating 24 columns. Create a numpy array called 'features' of shape (10000, 24) which contains our one-hot encoded feature vectors.\n",
    "You can follow the first example of the class' documentation:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. Your solution here ...\n",
    "\n",
    "print(features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12-markdown",
   "metadata": {},
   "source": [
    "# Exercise 1D\n",
    "Now we have everything we need: One-hot encoded features and the binary label 'married'.\n",
    "During the lecture you learned about binary logistic regression. Since our output variable is either 0 or 1, this seems like an ideal use case for it!\n",
    "Above, we imported LogisticRegression from sklearn. Have a look at the documentation, and implement it with default parameters for our data:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "Don't worry about test and train sets yet; we'll train our model on all the data and then evaluate it on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = data['married']\n",
    "#. Your solution here ...\n",
    "classifier.score(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14-markdown",
   "metadata": {},
   "source": [
    "# Exercise 1E\n",
    "76% accuracy! That doesn't sound too bad for a first attempt. But remember the zero-rate classifier? Let's have a look at what our baseline should be.\n",
    "Above, we plotted all possible outcome variables. Have a look what's more likely: married (1), or not married (0)? Then create a zero-rate classifier that always returns the most likely result.\n",
    "The estimated outcome value y is often denoted as Å·, which is why we call it y_hat here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_rate(x) -> int:\n",
    "    \"\"\"\n",
    "    Takes the input vector x and then completely disregards it.\n",
    "\n",
    "    Returns:\n",
    "        y(int): Whether or not the couple is married.\n",
    "    \"\"\"\n",
    "\n",
    "    #. Your solution here ...\n",
    "\n",
    "y_hat = [zero_rate(x) for x in features]\n",
    "# We imported accuracy_score from sklearn.metrics\n",
    "acc = accuracy_score(y, y_hat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16-markdown",
   "metadata": {},
   "source": [
    "Oh no, our zero-rate classifier is just as accurate as our logistic regression classifier.\n",
    "It seems our standard logistic regression model could not predict marriage based on astrological signs with any accuracy higher than chance.\n",
    "Does that mean that the signs simply have to effect on courting outcome? That would perhaps be the conclusion if this was astronomy class, but we wouldn't give you such a boring dataset for classification class would we?\n",
    "Assume there is some way in which the signs of the two partners affect their relationship. How come our model did not pick up on those?\n",
    "Can you think of a way in which the features could be re-coded so that logistic regression would predict the outcome with higher accuracy?\n",
    "Hint: A possible solution is shown in the next code cell. Try to think of one yourself first, but if you cannot, figure out why the sample solution works and then explain it here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17-markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18-markdown",
   "metadata": {},
   "source": [
    "# Question 1: (1 point, 30-150 words)\n",
    "Why did logistic regression not achieve useful accuracy? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19-markdown",
   "metadata": {},
   "source": [
    "# Answer Question 1:\n",
    "---SAMPLE ANSWER---\n",
    "Our model allows no interaction between input features. If the predictive power comes from the combination of two signs, we would need to code for sign-pairs, of which there are 12*12=144 instead of 24.\n",
    "---END SAMPLE ANSWER---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sign pairs for each possible combination\n",
    "sign_combination = data['sign_a'] + '-' + data['sign_b']\n",
    "# Shape them into an array with n samples and a single feature\n",
    "sign_combination = np.asarray(sign_combination).reshape(-1, 1)\n",
    "# One-hot encode\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(sign_combination)\n",
    "features = enc.transform(sign_combination).toarray()\n",
    "# Train and evaluate our classifier on these new features\n",
    "X = features\n",
    "y = data['married']\n",
    "classifier = LogisticRegression(random_state=0).fit(X, y)\n",
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21-markdown",
   "metadata": {},
   "source": [
    "This seems to have marginally improved the accuracy of our model. Let's see if we can improve it further by building more complex models and taking more information into account.\n",
    "\n",
    "Another variable we have available is each person's last tarot reading. Let's see if we can improve out model by including this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the tarot information from persons to our data\n",
    "data['tarot_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['tarot'].iat[0])\n",
    "data['tarot_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['tarot'].iat[0])\n",
    "\n",
    "# Add the tarot columns to your features\n",
    "features = np.c_[features, data['tarot_a'].tolist()]\n",
    "features = np.c_[features, data['tarot_b'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate our classifier on these new features\n",
    "X = features\n",
    "y = data['married']\n",
    "classifier = LogisticRegression(random_state=0, max_iter=300).fit(X, y)\n",
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24-markdown",
   "metadata": {},
   "source": [
    "This doesn't seem to significantly increase our accuracy. Maybe the variable isn't very useful, or maybe we are not using it right. Let's explore a bit.\n",
    "First, let's plot the distribution over values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['tarot_a'], bins=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26-markdown",
   "metadata": {},
   "source": [
    "The different tarot cards seem more or less uniformly distributed.\n",
    "Let's color this plot by outcome to see if there is really no effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='tarot_b', hue='outcome', bins=22, multiple='stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28-markdown",
   "metadata": {},
   "source": [
    "# Question 2: (2 points, 50-200 words)\n",
    "Explain what you see in the histogram above. What conclusion about the effect of tarot cards on partnership outcomes can you detect visually? If there are any effects, how might you take them into account, since using a numerical regressor for tarot seemed not to work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29-markdown",
   "metadata": {},
   "source": [
    "# Answer Question 2:\n",
    "---SAMPLE ANSWER---\n",
    "Most tarot values seem not to significantly affect the overall outcome. However, there are two values for which the outcome clearly differs: 6, and 13. (If students look them up, these correspond to \"love\" and \"death\"). 6 has a strong positive effect, leading to more marriage outcomes. 13 seems to have a negative effect, leading to more break-ups.\n",
    "Rather than treating tarot as a continuous variable, it must be treated as categorical. One-hot encoding could be used, however, an even better solution may be to only one-hot encode the two important variables 6 and 13.\n",
    "---END SAMPLE ANSWER---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reimports the data. You can use to reset your data in case you manipulated it earlier.\n",
    "# It also adds two additional features which we have not previously used\n",
    "# DO NOT CHANGE this function; it will be used when evaluating your code below.\n",
    "def load_data(couples_file = 'sem3_topic4_logreg_formative1_data1.csv', persons_file = 'sem3_topic4_logreg_formative1_data2.csv'):\n",
    "    couples = pd.read_csv(couples_file)\n",
    "    persons = pd.read_csv(persons_file)\n",
    "    data = couples.copy()\n",
    "    data['sign_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['sign'].iat[0])\n",
    "    data['sign_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['sign'].iat[0])\n",
    "    data['tarot_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['tarot'].iat[0])\n",
    "    data['tarot_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['tarot'].iat[0])\n",
    "    data['color_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['favorite_color'].iat[0])\n",
    "    data['color_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['favorite_color'].iat[0])\n",
    "    data['animal_a'] = couples['person_a'].apply(lambda x: persons[persons['id'] == x]['favorite_animal'].iat[0])\n",
    "    data['animal_b'] = couples['person_b'].apply(lambda x: persons[persons['id'] == x]['favorite_animal'].iat[0])\n",
    "    return data\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31-markdown",
   "metadata": {},
   "source": [
    "# Exercise 2A\n",
    "Complete the functions below. You have already written most of the required code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_outcome(data):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        np.array of shape (n_samples)\n",
    "    \"\"\"\n",
    "    # This is \n",
    "    # Insert the code you wrote above which one-hot encodes the marriage status here\n",
    "    #. Your solution here ...\n",
    "    return np.array(data['married'])\n",
    "\n",
    "# This function applies your transformations to the data.\n",
    "# You can improve this function with any transformations you think improve the data for ML.\n",
    "def transform_features(data):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        np.array of shape (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    # This is our code from above which one-hot encodes the sign combiation\n",
    "    sign_combination = data['sign_a'] + '-' + data['sign_b']\n",
    "    sign_combination = np.asarray(sign_combination).reshape(-1, 1)\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(sign_combination)\n",
    "    sign_features = enc.transform(sign_combination).toarray()\n",
    "    # Write code here which transforms tarot_a and tarot_b into useful features.\n",
    "    # Create a variable called tarot_features which is a numpy array of dimensions (n_samples, n_features)\n",
    "    #. Your solution here ...\n",
    "    # Insert any additional features you'd like to add to your model here.\n",
    "    # These can be additional transformations of the variables used so far, or can use the variables we have not included so far.\n",
    "\n",
    "    # All features are combined here. If you generated more features, add them to the line below.\n",
    "    features = np.hstack((sign_features, tarot_features))\n",
    "    return features\n",
    "    \n",
    "y = transform_outcome(data)\n",
    "X = transform_features(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33-markdown",
   "metadata": {},
   "source": [
    "Improve your transform_features() function until logistic regression based on your features achieves an accuracy of at least 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run logistic regression with the new features you created with the function above.\n",
    "classifier = LogisticRegression(random_state=0, max_iter=300).fit(X, y)\n",
    "classifier.score(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35-markdown",
   "metadata": {},
   "source": [
    "# Exercise 2B\n",
    "We've tinkered quite a bit with our features now. What about our classification model? Regression is one of the supervised ML techniques you have learned, but there are of course many others.\n",
    "While each technique requires understanding to apply it well, technically implementing them is made quite easy by sklearn, especially when using default hyperparameters and optimization.\n",
    "Show us that you know how to use online documentation to implement other ML models below. These two classifiers should also achieve 80% accuracy or higher.\n",
    "First, implement a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same features which you used for regression above, implement a random forest classifier and print the accuracy score.\n",
    "# Make sure it is called rf_classifier\n",
    "rf_classifier = ...\n",
    "#. Your solution here ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37-markdown",
   "metadata": {},
   "source": [
    "# Exercise 2C\n",
    "Second, implement a neural network classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same features which you used for regression above, implement a neural network, specifically a multilayer perceptron classifier, and print the accuracy score.\n",
    "# Implement a perceptron with at least 2 hidden layers, and preferably one which can be trained in a few seconds on an average laptop.\n",
    "# Make sure it is named nn_classifier\n",
    "nn_classifier = ...\n",
    "#. Your solution here ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-39-markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "So far, you have trained your models on all available data. This means that while you may achieve a great fit to the data you have, your model may be overfitted and perform poorly on new, unseen data. This final exercise will be evaluated with couples and individuals which you do not have access to. They are from the same population as your sample, so your model should work fine if you don't overfit. Implement any sklearn classification model you like (logistic regression recommended) with a test/train(/evaluate) split or cross-validation.\n",
    "\n",
    "Your model will be evaluated by accuracy score, so try to achieve as high a score as possible while avoiding overfitting.\n",
    "Please make sure your model is trained in a reasonable time frame on an average laptop (a few minutes maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are changing your features, either change the function transform_features above, or implement a new function named transform_features!\n",
    "# The unseen test data will be transformed by this function also!\n",
    "def transform_features(data):\n",
    "    #. Your solution here ...\n",
    "    return features\n",
    "\n",
    "# Implement your model here. Make sure it is named final_classifier\n",
    "X = transform_features(data)\n",
    "y = transform_outcome(data)\n",
    "final_classifier = ...\n",
    "\n",
    "#. Your solution here ...\n",
    "\n",
    "training_results = final_classifier.score(X, y)\n",
    "print(f'Accuracy on known data: {training_results}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-41-markdown",
   "metadata": {},
   "source": [
    "Well done, you've completed all the exercises. Make sure to restart your kernel and rerun all cells once before submitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
