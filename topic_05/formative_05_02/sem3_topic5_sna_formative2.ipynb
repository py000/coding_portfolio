{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0-markdown",
   "metadata": {},
   "source": [
    "# Semester 3 Coding Portfolio Topic 5 Formative Part 2/2:\n",
    "# Social networks 2: Complex and dynamical networks using Python and networkx\n",
    "\n",
    "This notebook covers the following topics:\n",
    " - Simulation with networks\n",
    "\n",
    "This notebook is expected to take around 5 hours to complete:\n",
    " - 2 hours for the formative part\n",
    " - 3 hours of self-study on the topics covered by this notebook\n",
    "\n",
    "Like all topics in this portfolio, this topic is split into two sections:\n",
    " - Formative \n",
    " - Summative\n",
    "\n",
    "<b>Formative section</b><br>\n",
    "Simply complete the given functions such that they pass the automated tests. This part is graded Pass/Fail; you must get 100% correct!\n",
    "You can submit your notebook through Canvas as often as you like. Make sure to start doing so early to insure that your code passes all tests!\n",
    "You may ask for help from fellow students and TAs on this section, and solutions might be provided later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1-markdown",
   "metadata": {},
   "source": [
    "In this workshop, we will focus on generating networks through code, and seeing some of the interesting and at times unexpected dynamics of networks.\n",
    "\n",
    "We will learn how to generate network using algorithms, and how the algorithms shape the properties of these networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all necessary packages first to avoid kernel restarts\n",
    "# This ensures all dependencies are available before running the notebook\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# List of required packages for this notebook\n",
    "required_packages = [\n",
    "    'numpy',\n",
    "    'networkx',\n",
    "    'matplotlib',\n",
    "    'scipy'\n",
    "]\n",
    "\n",
    "# Install packages that are not already installed\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"\u2713 {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "        print(f\"\u2713 {package} installed successfully\")\n",
    "\n",
    "print(\"\\nAll packages are ready! You can now run the notebook without restarting the kernel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports. Make sure your solution does not import any third-party modules not imported here!\n",
    "import random\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3-markdown",
   "metadata": {},
   "source": [
    "# 1. Small world simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4-markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will start with a geographical network, in which each node is connected to their four closest neighbhors, in a big circle.\n",
    "\n",
    "We will then see how the average shortest path depends on the number of edges we randomize in this network.\n",
    "\n",
    "The aim of this exercise is to see how nearly universal the small-world phenomenon is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circle network\n",
    "def create_circle_network(num_nodes=1000):\n",
    "    # This is code creates a simple circular network, were each node is connected to their neighbors \n",
    "    # Create an empty graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes and edges to create a circular network\n",
    "    for i in range(num_nodes):\n",
    "        G.add_node(i)\n",
    "        G.add_edge(i, (i + 1) % num_nodes)  # Connect each node to its neighbor, using modulo for circular connection\n",
    "        G.add_edge(i, (i + 2) % num_nodes)  # Connect each node to its second neighbor, using modulo for circular connection\n",
    "    \n",
    "    # Draw the network\n",
    "    nx.draw_circular(G, with_labels=True, node_color='lightblue', node_size=20, font_size=5)\n",
    "    plt.title(f\"Random Network with {num_nodes} Nodes\")\n",
    "    plt.show()\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = create_circle_network()\n",
    "print(f'The average shortest path between two nodes in this network is {nx.average_shortest_path_length(G)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7-markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "Your task is to answer: *What fraction of edges would you need to replace with random edges for the average shortest path to drop to 1/10 of this value* (i.e. 12.5)? Write code to replace the edges one by one by a random edge. For each edge removed, measure the new average shortest path. Plot the average shortest path as a function of the fraction of edges that are randomized. How do you interpret your finding? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_small_world_randomization(num_nodes=1000, max_iterations=100, target_path_length=12.5):\n",
    "    \"\"\"Simulate small world phenomenon by randomizing edges in a circle network.\n",
    "    \n",
    "    Args:\n",
    "        num_nodes: Number of nodes in the network\n",
    "        max_iterations: Maximum number of edges to randomize\n",
    "        target_path_length: Target average shortest path length to achieve\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (fractions, lengths, threshold_fraction) where fractions is list of edge \n",
    "               fraction randomized, lengths is list of average path lengths, and \n",
    "               threshold_fraction is when target was reached\n",
    "    \"\"\"\n",
    "    # Step 1: Create the initial circle network (each node connected to 4 nearest neighbors)\n",
    "    # This creates a regular network structure where nodes are arranged in a circle\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add all nodes to the graph\n",
    "    for i in range(num_nodes):\n",
    "        G.add_node(i)\n",
    "    \n",
    "    # Connect each node to its 4 nearest neighbors (2 on each side)\n",
    "    # This creates a regular lattice structure in a circular arrangement\n",
    "    for i in range(num_nodes):\n",
    "        # Connect to immediate neighbor (i+1 mod num_nodes wraps around)\n",
    "        G.add_edge(i, (i + 1) % num_nodes)\n",
    "        # Connect to second neighbor (i+2 mod num_nodes)\n",
    "        G.add_edge(i, (i + 2) % num_nodes)\n",
    "    \n",
    "    # Calculate total number of edges in the initial network\n",
    "    total_edges = G.number_of_edges()\n",
    "    \n",
    "    # Step 2: Initialize lists to track our measurements\n",
    "    fractions = []  # Will store the fraction of edges that have been randomized\n",
    "    lengths = []    # Will store the average shortest path length at each step\n",
    "    threshold_fraction = None  # Will store the fraction when target path length is reached\n",
    "    \n",
    "    # Step 3: Iteratively randomize edges and measure the effect\n",
    "    for iteration in range(max_iterations):\n",
    "        # Get all current edges as a list (we need to convert to list to sample from it)\n",
    "        edges_list = list(G.edges())\n",
    "        \n",
    "        # If no edges remain, break (shouldn't happen, but safety check)\n",
    "        if len(edges_list) == 0:\n",
    "            break\n",
    "        \n",
    "        # Randomly select an edge to remove\n",
    "        # This edge represents a local connection in our circle network\n",
    "        edge_to_remove = random.choice(edges_list)\n",
    "        node1, node2 = edge_to_remove\n",
    "        \n",
    "        # Remove the selected edge from the network\n",
    "        # This breaks a local connection\n",
    "        G.remove_edge(node1, node2)\n",
    "        \n",
    "        # Step 4: Add a new random edge to replace the removed one\n",
    "        # This creates a \"long-range\" connection that can dramatically reduce path lengths\n",
    "        # We need to ensure we don't create self-loops or duplicate edges\n",
    "        all_nodes = list(G.nodes())\n",
    "        \n",
    "        # Find two random nodes that are not already connected\n",
    "        # Keep trying until we find a valid pair\n",
    "        attempts = 0\n",
    "        while attempts < 100:  # Safety limit to avoid infinite loops\n",
    "            new_node1 = random.choice(all_nodes)\n",
    "            new_node2 = random.choice(all_nodes)\n",
    "            \n",
    "            # Check if this is a valid new edge:\n",
    "            # - Nodes must be different (no self-loops)\n",
    "            # - Edge must not already exist\n",
    "            if new_node1 != new_node2 and not G.has_edge(new_node1, new_node2):\n",
    "                G.add_edge(new_node1, new_node2)\n",
    "                break\n",
    "            attempts += 1\n",
    "        \n",
    "        # Step 5: Calculate the average shortest path length after this randomization\n",
    "        # This measures how \"small\" the world has become (how many steps on average to reach any node)\n",
    "        # Note: This can be computationally expensive for large networks\n",
    "        if nx.is_connected(G):  # Only calculate if network is still connected\n",
    "            avg_path_length = nx.average_shortest_path_length(G)\n",
    "        else:\n",
    "            # If network is disconnected, we can't calculate average path length\n",
    "            # In this case, we'll use a large value or skip this iteration\n",
    "            avg_path_length = float('inf')\n",
    "        \n",
    "        # Step 6: Calculate what fraction of edges have been randomized so far\n",
    "        # We divide by total_edges to get a fraction between 0 and 1\n",
    "        fraction_randomized = (iteration + 1) / total_edges\n",
    "        \n",
    "        # Store our measurements\n",
    "        fractions.append(fraction_randomized)\n",
    "        lengths.append(avg_path_length)\n",
    "        \n",
    "        # Step 7: Check if we've reached the target path length\n",
    "        # This is the \"small world\" threshold - when path length drops significantly\n",
    "        if threshold_fraction is None and avg_path_length <= target_path_length:\n",
    "            threshold_fraction = fraction_randomized\n",
    "    \n",
    "    \n",
    "    plt.plot(fractions, lengths)\n",
    "    plt.xlabel('Fraction of Edges Randomized')\n",
    "    plt.ylabel('Average Shortest Path Length')\n",
    "    plt.title('Small World Phenomenon')\n",
    "    plt.show()\n",
    "    \n",
    "    return fractions, lengths, threshold_fraction\n",
    "\n",
    "fractions, lengths, threshold_fraction = simulate_small_world_randomization()\n",
    "\n",
    "# BEGIN TESTS\n",
    "# @name(\"Simulation Structure\")\n",
    "# @description(\"Check that the simulation returns correct data structures\")\n",
    "def test_simulation_structure():\n",
    "    test_fractions, test_lengths, test_threshold = simulate_small_world_randomization(num_nodes=100, max_iterations=50, target_path_length=5.0)\n",
    "    assert isinstance(test_fractions, list), \"fractions should be a list\"\n",
    "    assert isinstance(test_lengths, list), \"lengths should be a list\"\n",
    "    assert len(test_fractions) == len(test_lengths), \"fractions and lengths should have same length\"\n",
    "    assert len(test_fractions) == 50, \"Should have exactly 50 iterations\"\n",
    "test_simulation_structure()\n",
    "\n",
    "# @name(\"Path Length Reduction\")\n",
    "# @description(\"Check that average path length decreases as edges are randomized\")\n",
    "def test_path_length_reduction():\n",
    "    test_fractions, test_lengths, test_threshold = simulate_small_world_randomization(num_nodes=100, max_iterations=50, target_path_length=5.0)\n",
    "    # Path length should generally decrease\n",
    "    assert test_lengths[-1] < test_lengths[0], \"Average path length should decrease after randomization\"\n",
    "test_path_length_reduction()\n",
    "\n",
    "# @name(\"Threshold Detection\")\n",
    "# @description(\"Check that threshold fraction is correctly detected\")\n",
    "def test_threshold_detection():\n",
    "    test_fractions, test_lengths, test_threshold = simulate_small_world_randomization(num_nodes=100, max_iterations=50, target_path_length=5.0)\n",
    "    if test_threshold is not None:\n",
    "        assert 0 <= test_threshold <= 1, \"Threshold fraction should be between 0 and 1\"\n",
    "        threshold_idx = test_fractions.index(test_threshold)\n",
    "        assert test_lengths[threshold_idx] < 5.0, \"Path length at threshold should be below target\"\n",
    "test_threshold_detection()\n",
    "# END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9-markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling how we make friends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10-markdown",
   "metadata": {},
   "source": [
    "Let's think about different models for how we make friends, and examine the type of social network that this results in.\n",
    "\n",
    "### Model 1: We meet random people\n",
    "One is just by meeting people by random. This would suggest just adding edges between two randomly selected nodes until we have as many edges that we want.\n",
    "\n",
    "This is called an Erdos-Renyi network.\n",
    "\n",
    "#### Exercise 2A: \n",
    "1. Write code for a network in which the nodes are connected to other nodes by random.\n",
    "2. Plot the degree distribution. You have come across this distribution before. What type of distribution is it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random network\n",
    "def create_random_network(num_nodes, num_edges_per_node):\n",
    "    \"\"\"Create a random Erdos-Renyi network.\n",
    "    \n",
    "    Args:\n",
    "        num_nodes: Number of nodes in the network\n",
    "        num_edges_per_node: Average number of edges per node\n",
    "        \n",
    "    Returns:\n",
    "        NetworkX Graph object\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add the nodes\n",
    "    for i in range(num_nodes):\n",
    "        G.add_node(i)\n",
    "\n",
    "    # Step 3: Calculate total number of edges we want to add\n",
    "    # If each node should have num_edges_per_node edges on average,\n",
    "    # then total edges = num_nodes * num_edges_per_node\n",
    "    total_edges_to_add = num_nodes * num_edges_per_node\n",
    "    \n",
    "    # Step 4: Add random edges until we reach the target number\n",
    "    # We use a while loop because some random pairs might already be connected\n",
    "    edges_added = 0\n",
    "    max_attempts = total_edges_to_add * 10  # Safety limit to avoid infinite loops\n",
    "        \n",
    "    while edges_added < total_edges_to_add and max_attempts > 0:\n",
    "        # Randomly select two different nodes\n",
    "        node1 = random.randint(0, num_nodes - 1)\n",
    "        node2 = random.randint(0, num_nodes - 1)\n",
    "        \n",
    "        # Make sure nodes are different (no self-loops)\n",
    "        if node1 == node2:\n",
    "            max_attempts -= 1\n",
    "            continue\n",
    "        \n",
    "        # Check if this edge already exists\n",
    "        # If not, add it to the graph\n",
    "        if not G.has_edge(node1, node2):\n",
    "            G.add_edge(node1, node2)\n",
    "            edges_added += 1\n",
    "        \n",
    "        max_attempts -= 1\n",
    "    \n",
    "    # Note: Due to randomness, we might not reach exactly total_edges_to_add\n",
    "    # if the network becomes very dense, but this is fine for our purposes\n",
    "    \n",
    "\n",
    "    # Draw the network\n",
    "    nx.draw(G, with_labels=True, node_color='lightblue', node_size=20, font_size=5)\n",
    "    plt.title(f\"Random Network with {num_nodes} Nodes\")\n",
    "    plt.show()\n",
    "    return G\n",
    "\n",
    "G = create_random_network(5000, 25)\n",
    "\n",
    "# BEGIN TESTS\n",
    "# @name(\"Network Creation\")\n",
    "# @description(\"Check that the network is created with correct number of nodes\")\n",
    "def test_network_creation():\n",
    "    test_G = create_random_network(100, 5)\n",
    "    assert test_G.number_of_nodes() == 100, f\"Network should have exactly 100 nodes, but has {test_G.number_of_nodes()}\"\n",
    "    assert isinstance(test_G, nx.Graph), \"Should return a NetworkX Graph\"\n",
    "test_network_creation()\n",
    "\n",
    "# @name(\"Edge Addition\")\n",
    "# @description(\"Check that edges are added to the network\")\n",
    "def test_edge_addition():\n",
    "    test_G = create_random_network(50, 10)\n",
    "    assert test_G.number_of_edges() > 0, \"Network should have edges\"\n",
    "    # Should have approximately num_edges_per_node * num_nodes edges (some may be duplicates)\n",
    "    assert test_G.number_of_edges() <= 50 * 10, \"Should not exceed maximum possible edges added\"\n",
    "test_edge_addition()\n",
    "\n",
    "# @name(\"Randomness Check\")\n",
    "# @description(\"Check that edge generation is random by comparing two networks\")\n",
    "def test_randomness():\n",
    "    test_G1 = create_random_network(30, 3)\n",
    "    test_G2 = create_random_network(30, 3)\n",
    "    edges1 = set(test_G1.edges())\n",
    "    edges2 = set(test_G2.edges())\n",
    "    # Networks should not be identical (extremely unlikely with random generation)\n",
    "    assert edges1 != edges2, \"Graph generation is not random; the function generates identical graphs\"\n",
    "test_randomness()\n",
    "# END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12-markdown",
   "metadata": {},
   "source": [
    "### Exercise 2B:\n",
    "Let's plot the degree distribution of this network. To do so, we create a histogram of the frequency of each number of degrees. \n",
    "\n",
    "The degree distribution is a highly important measure, as it shows how equal the network is, and how dominated it is by a few nodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the degree distribution \n",
    "def plot_degree_distribution(G):\n",
    "    \"\"\"Calculate and plot the degree distribution of a network.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX Graph object\n",
    "        \n",
    "    Returns:\n",
    "        list: List of degrees for all nodes\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate the degree of each node in the network\n",
    "    # The degree of a node is simply the number of neighbors it has\n",
    "    # NetworkX provides G.degree() which returns a view of (node, degree) pairs\n",
    "    \n",
    "    # Extract just the degree values (not the node IDs)\n",
    "    # We iterate through all nodes and get their degree\n",
    "    degrees = [degree for node, degree in G.degree()]\n",
    "    \n",
    "    # Alternative approach (more explicit):\n",
    "    # degrees = []\n",
    "    # for node in G.nodes():\n",
    "    #     degree = G.degree(node)  # Number of edges connected to this node\n",
    "    #     degrees.append(degree)\n",
    "    \n",
    "    \n",
    "    # Create the histogram of degrees\n",
    "    plt.hist(degrees, bins=range(min(degrees), max(degrees) + 2), align='left')\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Degree Distribution of the Network')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    return degrees\n",
    "\n",
    "degrees = plot_degree_distribution(G)\n",
    "\n",
    "# BEGIN TESTS\n",
    "# @name(\"Degree Calculation\")\n",
    "# @description(\"Check that degrees are correctly calculated\")\n",
    "def test_degree_calculation():\n",
    "    test_G = nx.Graph()\n",
    "    test_G.add_edges_from([(0, 1), (0, 2), (0, 3), (1, 2)])\n",
    "    test_degrees = plot_degree_distribution(test_G)\n",
    "    assert isinstance(test_degrees, list), \"Should return a list of degrees\"\n",
    "    assert len(test_degrees) == 4, \"Should have degree for each node\"\n",
    "    assert sorted(test_degrees) == [1, 2, 2, 3], \"Degrees should match expected values\"\n",
    "test_degree_calculation()\n",
    "\n",
    "# @name(\"Degree List Structure\")\n",
    "# @description(\"Check that all degrees are non-negative integers\")\n",
    "def test_degree_list_structure():\n",
    "    test_G = create_random_network(50, 3)\n",
    "    test_degrees = plot_degree_distribution(test_G)\n",
    "    assert all(isinstance(d, int) for d in test_degrees), \"All degrees should be integers\"\n",
    "    assert all(d >= 0 for d in test_degrees), \"All degrees should be non-negative\"\n",
    "test_degree_list_structure()\n",
    "\n",
    "# @name(\"Degree Count\")\n",
    "# @description(\"Check that we have one degree value per node\")\n",
    "def test_degree_count():\n",
    "    test_G = nx.complete_graph(10)\n",
    "    test_degrees = plot_degree_distribution(test_G)\n",
    "    assert len(test_degrees) == test_G.number_of_nodes(), \"Should have one degree per node\"\n",
    "    assert all(d == 9 for d in test_degrees), \"Complete graph should have all nodes with degree n-1\"\n",
    "test_degree_count()\n",
    "# END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: we can fit a normal distribution to it.\n",
    "# Sample data\n",
    "data = [degree for node, degree in G.degree()]\n",
    "\n",
    "# Plot histogram of the data\n",
    "plt.hist(data, bins=range(min(data), max(data) + 2), density=True, alpha=0.6, color='g')\n",
    "\n",
    "# List of candidate distributions\n",
    "distributions = [stats.norm] \n",
    "\n",
    "# Fit distributions to the data and plot\n",
    "for distribution in distributions:\n",
    "    # Fit distribution to data\n",
    "    params = distribution.fit(data)\n",
    "    \n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "    \n",
    "    # Calculate fitted PDF and error with fit in distribution\n",
    "    pdf = distribution.pdf(np.linspace(min(data), max(data), 100), loc=loc, scale=scale, *arg)\n",
    "    plt.plot(np.linspace(min(data), max(data), 100), pdf, label=f\"{distribution.name}\")\n",
    "    plt.xlim([min(data) - 1, max(data) + 1])\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15-markdown",
   "metadata": {},
   "source": [
    "### Model 2: Friends make friends through friends\n",
    "\n",
    "The network we created, the nodes are connected randomly based on the nodes. But in most real-world networks, you make connections through your existing connections. For instance, the probability that you follow someone on Twitter depends on how many followers the person already has, since you are likely to encounter them through their followers.\n",
    "\n",
    "These degree distributions are ubiquitous, and characterize nearly all networks around us, including link between websites, flights connecting airports, and so on.\n",
    "\n",
    "In most social networks, nodes build connections based on their existing connections. This is called \"preferential attachment\".\n",
    "\n",
    "#### Exercise 2C:\n",
    "1. You will simulate the growth of a social media network. The network will have N nodes. These join one at the time. At each step, add one new node, then sample M existing nodes based on their edges, and add num_edges_per_node edges to these.\n",
    "2. Plot the resulting degree distribution. What type of distribution is this? What does it mean that networks have this type of structure?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_network_by_edges(num_nodes, num_edges_per_node):\n",
    "    \"\"\"Create a scale-free network using preferential attachment.\n",
    "    \n",
    "\n",
    "\n",
    "    Args:\n",
    "        num_nodes: Number of nodes in the network\n",
    "        num_edges_per_node: Number of edges each new node creates\n",
    "        \n",
    "    Returns:\n",
    "        NetworkX Graph object\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize the network with a small starting structure\n",
    "    # We start with just 2 nodes connected by an edge\n",
    "    # This gives us a base to build upon\n",
    "    G = nx.Graph()\n",
    "    G.add_node(0)\n",
    "    G.add_node(1)\n",
    "    G.add_edge(0, 1)\n",
    "    \n",
    "    # Step 2: Add nodes one by one using preferential attachment\n",
    "    # This simulates how networks grow in real life (e.g., people joining a social network)\n",
    "    for new_node_id in range(2, num_nodes):\n",
    "        # Add the new node to the network\n",
    "        G.add_node(new_node_id)\n",
    "        \n",
    "        # Step 3: Implement preferential attachment\n",
    "        # The new node will connect to num_edges_per_node existing nodes\n",
    "        # The probability of connecting to an existing node is proportional to its degree\n",
    "        # This means popular nodes (with many connections) are more likely to get new connections\n",
    "        \n",
    "        # We need to sample existing nodes with probability proportional to their degree\n",
    "        # One way to do this is to create a list where each node appears as many times\n",
    "        # as its degree, then randomly sample from that list\n",
    "        \n",
    "        # Get all existing nodes (all nodes except the one we just added)\n",
    "        existing_nodes = list(range(new_node_id))\n",
    "        \n",
    "        # Create a list for weighted random sampling\n",
    "        # Each existing node appears in the list a number of times equal to its degree\n",
    "        # This makes nodes with higher degree more likely to be selected\n",
    "        weighted_node_list = []\n",
    "        for node in existing_nodes:\n",
    "            degree = G.degree(node)\n",
    "            # Add this node to the list 'degree' times\n",
    "            # If a node has degree 0, it won't be added (isolated nodes can't be selected)\n",
    "            weighted_node_list.extend([node] * degree)\n",
    "        \n",
    "        # If no nodes have edges yet (shouldn't happen after initial setup), \n",
    "        # just connect to random nodes\n",
    "        if len(weighted_node_list) == 0:\n",
    "            # Fallback: connect to random existing nodes\n",
    "            targets = random.sample(existing_nodes, min(num_edges_per_node, len(existing_nodes)))\n",
    "        else:\n",
    "            # Step 4: Sample nodes from the weighted list\n",
    "            # We sample without replacement to avoid duplicate edges\n",
    "            # If we need more connections than available nodes, we take all available\n",
    "            num_connections = min(num_edges_per_node, len(weighted_node_list))\n",
    "            selected_targets = random.sample(weighted_node_list, num_connections)\n",
    "            \n",
    "            # Remove duplicates (in case same node was selected multiple times)\n",
    "            targets = list(set(selected_targets))\n",
    "            \n",
    "            # If we still need more connections (after removing duplicates),\n",
    "            # add more random nodes from existing nodes\n",
    "            while len(targets) < num_edges_per_node and len(targets) < len(existing_nodes):\n",
    "                additional_target = random.choice(existing_nodes)\n",
    "                if additional_target not in targets:\n",
    "                    targets.append(additional_target)\n",
    "        \n",
    "        # Step 5: Add edges from the new node to the selected target nodes\n",
    "        for target in targets:\n",
    "            G.add_edge(new_node_id, target)\n",
    "    \n",
    "    \n",
    "    # Draw the network\n",
    "    nx.draw(G, with_labels=True, node_color='lightblue', node_size=20, font_size=5)\n",
    "    plt.show()\n",
    "    return G\n",
    "\n",
    "G = create_random_network_by_edges(1000, 10)\n",
    "degrees = plot_degree_distribution(G)\n",
    "\n",
    "# BEGIN TESTS\n",
    "# @name(\"Network Initialization\")\n",
    "# @description(\"Check that the network starts with correct structure\")\n",
    "def test_network_initialization():\n",
    "    test_G = create_random_network_by_edges(10, 2)\n",
    "    assert test_G.number_of_nodes() == 10, \"The function generates a network with incorrect number of nodes\"\n",
    "    assert test_G.number_of_edges() > 0, \"The network should have edges\"\n",
    "test_network_initialization()\n",
    "\n",
    "# @name(\"Preferential Attachment\")\n",
    "# @description(\"Check that preferential attachment creates scale-free properties\")\n",
    "def test_preferential_attachment():\n",
    "    test_G = create_random_network_by_edges(100, 2)\n",
    "    degrees = [degree for node, degree in test_G.degree()]\n",
    "    # Scale-free networks should have some high-degree hubs\n",
    "    max_degree = max(degrees)\n",
    "    avg_degree = sum(degrees) / len(degrees)\n",
    "    assert max_degree > avg_degree * 2, \"Should have hub nodes with degree much higher than average\"\n",
    "test_preferential_attachment()\n",
    "\n",
    "# @name(\"Edge Count\")\n",
    "# @description(\"Check that edges are added correctly\")\n",
    "def test_edge_count():\n",
    "    test_G = create_random_network_by_edges(50, 3)\n",
    "    # Starting with 1 edge, then adding 3 edges for nodes 2 through 49\n",
    "    assert test_G.number_of_edges() >= 100, f\"The function generates sufficient number of edges\"\n",
    "test_edge_count()\n",
    "\n",
    "# @name(\"Connectivity\")\n",
    "# @description(\"Check that the network is connected\")\n",
    "def test_connectivity():\n",
    "    test_G = create_random_network_by_edges(30, 2)\n",
    "    assert nx.is_connected(test_G), \"Preferential attachment network should be connected\"\n",
    "test_connectivity()\n",
    "# END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's straight on a log! \n",
    "plt.hist(data, bins=range(min(data), max(data) + 2), density=True, alpha=0.6, color='g', log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18-markdown",
   "metadata": {},
   "source": [
    "Power law distribution: It's a scale-free network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19-markdown",
   "metadata": {},
   "source": [
    "# 3. Epidemics in networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20-markdown",
   "metadata": {},
   "source": [
    "Networks also allow us to model dynamic phenomena, such as the spread of ideas, habits, or disease through networks. \n",
    "\n",
    "The structure of the network is central to how these spread. For instance, if Twitter changes how followingship is made, this will affect the dynamics of virality on Twitter.\n",
    "\n",
    "The same accounts to disease spread. The SIR model is a classic framework used in epidemiology to understand how diseases spread through populations. SIR stands for Susceptible, Infected, and Recovered, which are the three possible states of individuals in this model:\n",
    "\n",
    "- Susceptible (S): Individuals who have not yet contracted the disease and are vulnerable to infection.\n",
    "- Infected (I): Individuals who have contracted the disease and are capable of spreading it to susceptible individuals.\n",
    "- Recovered (R): Individuals who have recovered from the disease and are no longer susceptible to it. In some models, 'Recovered' can also include individuals who have died from the disease, as they are no longer part of the infection cycle.\n",
    "\n",
    "We are now going to look at how the spread of the disease depends on the network structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIR_simulation(G, initial_infected, infection_prob, recovery_prob):\n",
    "    # Initialize all nodes as susceptible\n",
    "    nx.set_node_attributes(G, 'S', 'state')\n",
    "\n",
    "    # Infect initial nodes\n",
    "    for node in initial_infected:\n",
    "        G.nodes[node]['state'] = 'I'\n",
    "\n",
    "    S, I, R = [], [], []\n",
    "    # for _ in range(steps):\n",
    "    while(True):\n",
    "        new_infected = []\n",
    "        new_recovered = []\n",
    "\n",
    "        # Spread the infection\n",
    "        for node in G:\n",
    "            if G.nodes[node]['state'] == 'I':\n",
    "                neighbors = list(G.neighbors(node))\n",
    "                for neighbor in neighbors:\n",
    "                    if G.nodes[neighbor]['state'] == 'S' and random.random() < infection_prob:\n",
    "                        new_infected.append(neighbor)\n",
    "\n",
    "                # Recover process\n",
    "                if random.random() < recovery_prob:\n",
    "                    new_recovered.append(node)\n",
    "\n",
    "        # Update the states\n",
    "        for node in new_infected:\n",
    "            G.nodes[node]['state'] = 'I'\n",
    "        for node in new_recovered:\n",
    "            G.nodes[node]['state'] = 'R'\n",
    "\n",
    "        S.append(sum(1 for n in G if G.nodes[n]['state'] == 'S'))\n",
    "        nr_infected = sum(1 for n in G if G.nodes[n]['state'] == 'I')\n",
    "        I.append(nr_infected)\n",
    "        R.append(sum(1 for n in G if G.nodes[n]['state'] == 'R'))\n",
    "        if nr_infected == 0:\n",
    "            break\n",
    "\n",
    "    return S, I, R\n",
    "\n",
    "def plot_network(G):\n",
    "    # Colors for nodes\n",
    "    colors = ['blue' if G.nodes[node]['state'] == 'S' else ('red' if G.nodes[node]['state'] == 'I' else 'green') for node in G]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw(G, node_color=colors, node_size=50, with_labels=False)\n",
    "    plt.show()\n",
    "\n",
    "# Parameters for the SIR simulation\n",
    "initial_infected_count = 5\n",
    "infection_prob = 0.02 \n",
    "recovery_prob = 0.1\n",
    "\n",
    "# Create different network types\n",
    "G = nx.watts_strogatz_graph(1000, 10, 0.1)    \n",
    "\n",
    "# Example run!\n",
    "initial_infected = random.sample(list(G.nodes()), initial_infected_count)\n",
    "S, I, R = SIR_simulation(G, initial_infected, infection_prob, recovery_prob)\n",
    "plot_network(G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22-markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "Your task is to compare how well a disease spreads in different network structures. In which network does the disease spread fastest? In which networks does the disease spread to the most nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Networks to compare\n",
    "\n",
    "# networks = {\n",
    "#         \"Scale-Free Network\": nx.barabasi_albert_graph(1000, 2),\n",
    "#         \"Small-World Network\": nx.watts_strogatz_graph(1000, 4, 0.1),\n",
    "#         \"Random Network\": nx.erdos_renyi_graph(1000, 0.05),\n",
    "#         \"Network with Communities\": nx.connected_caveman_graph(10, 100)\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sir_comparison(initial_infected_count=5, infection_prob=0.02, recovery_prob=0.1):\n",
    "    \"\"\"Run SIR simulations on different network types and compare spread dynamics.\n",
    "    \n",
    "    Args:\n",
    "        initial_infected_count: Number of initially infected nodes\n",
    "        infection_prob: Probability of infection spreading per contact\n",
    "        recovery_prob: Probability of recovery per time step\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary mapping network type to tuple of (S, I, R) time series\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize dictionary to store results for each network type\n",
    "    # Each entry will contain the time series of S, I, R values\n",
    "    results = {}\n",
    "    \n",
    "    # Step 2: Define the four network types we want to compare\n",
    "    # Each network has 1000 nodes for fair comparison\n",
    "    networks = {\n",
    "        \"Scale-Free Network\": nx.barabasi_albert_graph(1000, 2),\n",
    "        # Barab\u00e1si-Albert: Preferential attachment, creates hub nodes\n",
    "        # Parameter 2 means each new node connects to 2 existing nodes\n",
    "        \n",
    "        \"Small-World Network\": nx.watts_strogatz_graph(1000, 4, 0.1),\n",
    "        # Watts-Strogatz: Starts as regular lattice, then randomizes some edges\n",
    "        # Parameter 4: each node connected to 4 nearest neighbors initially\n",
    "        # Parameter 0.1: 10% of edges are randomized\n",
    "        \n",
    "        \"Random Network\": nx.erdos_renyi_graph(1000, 0.05),\n",
    "        # Erd\u0151s-R\u00e9nyi: Completely random connections\n",
    "        # Parameter 0.05: probability of edge between any two nodes is 5%\n",
    "        \n",
    "        \"Network with Communities\": nx.connected_caveman_graph(10, 100)\n",
    "        # Connected Caveman: Creates 10 communities of 100 nodes each\n",
    "        # Nodes are highly connected within communities, sparsely between\n",
    "    }\n",
    "    \n",
    "    # Step 3: Run SIR simulation on each network type\n",
    "    # We'll use the SIR_simulation function that was already defined earlier\n",
    "    for network_name, network_graph in networks.items():\n",
    "        # Create a copy of the network for this simulation\n",
    "        # This is important because SIR_simulation modifies the graph (adds node attributes)\n",
    "        G_copy = network_graph.copy()\n",
    "        \n",
    "        # Step 4: Randomly select initial infected nodes\n",
    "        # We want to start with the same number of infected nodes for fair comparison\n",
    "        all_nodes = list(G_copy.nodes())\n",
    "        initial_infected = random.sample(all_nodes, min(initial_infected_count, len(all_nodes)))\n",
    "        \n",
    "        # Step 5: Run the SIR simulation\n",
    "        # This will return three lists: S (susceptible count over time),\n",
    "        # I (infected count over time), and R (recovered count over time)\n",
    "        S, I, R = SIR_simulation(G_copy, initial_infected, infection_prob, recovery_prob)\n",
    "        \n",
    "        # Step 6: Store the results\n",
    "        # We store as a tuple so we can easily unpack it later for analysis\n",
    "        results[network_name] = (S, I, R)\n",
    "    \n",
    "    # Step 7: Return all results for comparison\n",
    "    # The caller can then plot or analyze these time series to see differences\n",
    "    \n",
    "    \n",
    "    return results\n",
    "\n",
    "results = run_sir_comparison()\n",
    "\n",
    "# BEGIN TESTS\n",
    "# @name(\"Results Structure\")\n",
    "# @description(\"Check that results contain all network types\")\n",
    "def test_results_structure():\n",
    "    test_results = run_sir_comparison(initial_infected_count=5, infection_prob=0.02, recovery_prob=0.1)\n",
    "    assert isinstance(test_results, dict), \"Results should be a dictionary\"\n",
    "    expected_networks = [\"Scale-Free Network\", \"Small-World Network\", \"Random Network\", \"Network with Communities\"]\n",
    "    for net_type in expected_networks:\n",
    "        assert net_type in test_results, f\"Results should include {net_type}\"\n",
    "test_results_structure()\n",
    "\n",
    "# @name(\"Time Series Data\")\n",
    "# @description(\"Check that each simulation returns valid time series\")\n",
    "def test_time_series_data():\n",
    "    test_results = run_sir_comparison(initial_infected_count=5, infection_prob=0.02, recovery_prob=0.1)\n",
    "    for net_type, (S, I, R) in test_results.items():\n",
    "        assert isinstance(S, list), f\"{net_type}: S should be a list\"\n",
    "        assert isinstance(I, list), f\"{net_type}: I should be a list\"\n",
    "        assert isinstance(R, list), f\"{net_type}: R should be a list\"\n",
    "        assert len(S) == len(I) == len(R), f\"{net_type}: S, I, R should have same length\"\n",
    "        assert len(S) > 0, f\"{net_type}: Time series should not be empty\"\n",
    "test_time_series_data()\n",
    "\n",
    "# @name(\"Conservation of Population\")\n",
    "# @description(\"Check that S + I + R = total population at each time step\")\n",
    "def test_conservation_of_population():\n",
    "    test_results = run_sir_comparison(initial_infected_count=5, infection_prob=0.02, recovery_prob=0.1)\n",
    "    for net_type, (S, I, R) in test_results.items():\n",
    "        total_population = S[0] + I[0] + R[0]\n",
    "        for i in range(len(S)):\n",
    "            assert S[i] + I[i] + R[i] == total_population, f\"{net_type}: Population should not change over time\"\n",
    "test_conservation_of_population()\n",
    "\n",
    "# @name(\"Epidemic Dynamics\")\n",
    "# @description(\"Check that epidemic eventually ends (I reaches 0)\")\n",
    "def test_epidemic_dynamics():\n",
    "    test_results = run_sir_comparison(initial_infected_count=5, infection_prob=0.02, recovery_prob=0.1)\n",
    "    for net_type, (S, I, R) in test_results.items():\n",
    "        assert I[-1] == 0, f\"{net_type}: Epidemic should end with no infected individuals\"\n",
    "        assert R[-1] > 0, f\"{net_type}: Some individuals should have recovered\"\n",
    "test_epidemic_dynamics()\n",
    "# END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25-markdown",
   "metadata": {},
   "source": [
    "# 4. Cascading failures in electricity grids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26-markdown",
   "metadata": {},
   "source": [
    "Cascading failures in electricity grids refer to a process where a failure in one part of the grid triggers a chain of failures throughout the system, leading to a large-scale power outage or blackout. The cascade often begins with a single failure or fault in one component of the grid, such as a transmission line, transformer, or generator. When a component fails, the electrical load it was carrying is redistributed to other parts of the grid. If this redistribution results in an excessive load on these components, they can also fail. Each subsequent failure puts additional strain on the system, causing more components to fail. This can create a domino effect, leading to widespread disconnections and outages.\n",
    "\n",
    "You are a terrorist and you want to attack the US electricity grid. You have acquired the network of nodes, and you want to find how you can do the most damage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml('sem3_topic5_sna_formative2_data.gml', label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The capacity of the nodes is proportional to their betweenness centrality\n",
    "pagerank = nx.pagerank(G)\n",
    "    \n",
    "# Set node attribute\n",
    "for node in G.nodes():\n",
    "    G.nodes[node]['load'] = pagerank[node] * random.uniform(10000, 20000)\n",
    "    G.nodes[node]['capacity'] = G.nodes[node]['load'] * random.uniform(1.3, 1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G,\"sem3_topic5_sna_formative2_data.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gexf('sem3_topic5_sna_formative2_data.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_grid():\n",
    "    # Create a random graph to simulate a grid\n",
    "    G = nx.read_gexf('sem3_topic5_sna_formative2_data.gexf')\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Reset the grid to unfailed status\n",
    "def reset_grid(G):\n",
    "    for node in G.nodes:\n",
    "        G.nodes[node]['current_load'] = G.nodes[node]['load']\n",
    "        G.nodes[node]['current_capacity'] = G.nodes[node]['capacity']\n",
    "        G.nodes[node]['failed'] = False\n",
    "\n",
    "# Fail a particular node\n",
    "def fail_node(G, neighbors_dict, node):\n",
    "    # Fail a node and redistribute its load\n",
    "    load_to_redistribute = G.nodes[node]['current_load']\n",
    "    G.nodes[node]['current_load'] = 0\n",
    "    G.nodes[node]['failed'] = True\n",
    "    neighbors = neighbors_dict[node]\n",
    "    load_distribution = load_to_redistribute / len(neighbors)\n",
    "    for neighbor in neighbors:\n",
    "        G.nodes[neighbor]['current_load'] += load_distribution\n",
    "\n",
    "# This code cascades the failure througout the network\n",
    "def cascade_failure(G, neighbors_dict):\n",
    "    failed = 0\n",
    "    overloaded = True\n",
    "    while overloaded:\n",
    "        overloaded = False\n",
    "        for node in list(G.nodes):\n",
    "            if not G.nodes[node]['failed'] and G.nodes[node]['current_load'] > G.nodes[node]['current_capacity']:\n",
    "                failed += 1\n",
    "                fail_node(G, neighbors_dict, node)\n",
    "                overloaded = True\n",
    "    return failed\n",
    "\n",
    "#Load graph \n",
    "G = initialize_grid()\n",
    "# Precompute neighbor lists for speed\n",
    "neighbors_dict = {node: list(G.neighbors(node)) for node in G.nodes}\n",
    "\n",
    "reset_grid(G)\n",
    "\n",
    "# Simulate initial failure\n",
    "initial_failure = random.choice(list(G.nodes))\n",
    "fail_node(G, neighbors_dict, initial_failure)\n",
    "\n",
    "# Simulate cascading failure\n",
    "failed_nodes = cascade_failure(G,neighbors_dict)\n",
    "print(f\"The cascade brought down {failed_nodes} nodes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32-markdown",
   "metadata": {},
   "source": [
    "### Exercise 4A\n",
    "Your task is to examine: \n",
    "\n",
    "1. What is the distribution of collapses when the node is selected at random?\n",
    "\n",
    "2. Which node results in the largest cascade? How many nodes are brought down when this is attacked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_random_cascade_distribution(num_simulations=50):\n",
    "    \"\"\"Analyze the distribution of cascade failures when initial failure is random.\n",
    "    \n",
    "    Args:\n",
    "        num_simulations: Number of random simulations to run\n",
    "        \n",
    "    Returns:\n",
    "        list: List of failure counts for each simulation\n",
    "    \"\"\"\n",
    "    # Step 1: Load the power grid network\n",
    "    # This network represents the structure of the electricity grid\n",
    "    G = initialize_grid()\n",
    "    \n",
    "    # Step 2: Precompute neighbor lists for efficiency\n",
    "    # This avoids repeatedly calling G.neighbors() during the cascade\n",
    "    # We create a dictionary mapping each node to its list of neighbors\n",
    "    neighbors_dict = {node: list(G.neighbors(node)) for node in G.nodes}\n",
    "    \n",
    "    # Step 3: Initialize list to store cascade outcomes\n",
    "    # Each outcome is the total number of nodes that failed in that simulation\n",
    "    outcomes = []\n",
    "    \n",
    "    # Step 4: Run multiple simulations with different random starting points\n",
    "    # This gives us a distribution of possible cascade sizes\n",
    "    for simulation in range(num_simulations):\n",
    "        # Step 5: Reset the grid to its initial state for each simulation\n",
    "        # This ensures each simulation starts with the same grid configuration\n",
    "        # (all nodes have their original load and capacity, none have failed)\n",
    "        reset_grid(G)\n",
    "        \n",
    "        # Step 6: Randomly select a node to fail initially\n",
    "        # This simulates a random failure event (e.g., equipment malfunction, attack)\n",
    "        all_nodes = list(G.nodes)\n",
    "        initial_failure_node = random.choice(all_nodes)\n",
    "        \n",
    "        # Step 7: Trigger the initial failure\n",
    "        # This redistributes the failed node's load to its neighbors\n",
    "        fail_node(G, neighbors_dict, initial_failure_node)\n",
    "        \n",
    "        # Step 8: Run the cascade simulation\n",
    "        # This function continues the cascade until no more nodes fail\n",
    "        # It returns the number of additional nodes that failed (excluding the initial one)\n",
    "        additional_failures = cascade_failure(G, neighbors_dict)\n",
    "        \n",
    "        # Step 9: Calculate total failures (initial + cascading)\n",
    "        # The initial failure counts as 1, plus all the cascading failures\n",
    "        total_failures = 1 + additional_failures\n",
    "        \n",
    "        # Step 10: Store the outcome\n",
    "        outcomes.append(total_failures)\n",
    "    \n",
    "    # Step 11: Return all outcomes\n",
    "    # This list can be used to create a histogram showing the distribution\n",
    "    # of cascade sizes, calculate statistics (mean, median, max), etc.\n",
    "    \n",
    "    \n",
    "    return outcomes\n",
    "\n",
    "outcomes = analyze_random_cascade_distribution()\n",
    "\n",
    "# BEGIN TESTS\n",
    "# @name(\"Simulation Count\")\n",
    "# @description(\"Check that correct number of simulations are run\")\n",
    "def test_simulation_count():\n",
    "    test_outcomes = analyze_random_cascade_distribution(num_simulations=10)\n",
    "    assert len(test_outcomes) == 10, \"Should run exactly 10 simulations\"\n",
    "    assert all(isinstance(x, int) for x in test_outcomes), \"All outcomes should be integers\"\n",
    "test_simulation_count()\n",
    "\n",
    "# @name(\"Cascade Values\")\n",
    "# @description(\"Check that cascade values are non-negative\")\n",
    "def test_cascade_values():\n",
    "    test_outcomes = analyze_random_cascade_distribution(num_simulations=20)\n",
    "    assert all(x >= 0 for x in test_outcomes), \"All cascade counts should be non-negative\"\n",
    "test_cascade_values()\n",
    "\n",
    "# @name(\"Variability\")\n",
    "# @description(\"Check that different simulations produce varied results\")\n",
    "def test_variability():\n",
    "    test_outcomes = analyze_random_cascade_distribution(num_simulations=30)\n",
    "    # With random selection, we should see some variability\n",
    "    # (not all outcomes identical unless network is trivial)\n",
    "    assert len(set(test_outcomes)) > 1 or len(test_outcomes) < 5, \"Should see some variability in cascade sizes\"\n",
    "test_variability()\n",
    "# END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34-markdown",
   "metadata": {},
   "source": [
    "### Exercise 4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_cascade_node():\n",
    "    \"\"\"Find which node causes the largest cascade when it fails.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (worst_node, max_failures, outcomes_dict) where worst_node is the node ID,\n",
    "               max_failures is the number of cascading failures, and outcomes_dict maps\n",
    "               all nodes to their cascade counts\n",
    "    \"\"\"\n",
    "    # Step 1: Load the power grid network\n",
    "    # This is the network structure we'll be testing\n",
    "    G = initialize_grid()\n",
    "    \n",
    "    # Step 2: Precompute neighbor lists for efficiency\n",
    "    # This speeds up the cascade simulation by avoiding repeated neighbor lookups\n",
    "    neighbors_dict = {node: list(G.neighbors(node)) for node in G.nodes}\n",
    "    \n",
    "    # Step 3: Initialize dictionary to store cascade outcomes\n",
    "    # Key: node ID, Value: total number of nodes that fail when this node fails\n",
    "    outcomes = {}\n",
    "    \n",
    "    # Step 4: Test each node in the network\n",
    "    # We systematically fail each node and measure the resulting cascade\n",
    "    for node_to_test in G.nodes():\n",
    "        # Step 5: Reset the grid to initial state for this test\n",
    "        # Each test must start with the same grid configuration\n",
    "        reset_grid(G)\n",
    "        \n",
    "        # Step 6: Fail the node we're testing\n",
    "        # This triggers the initial failure and redistributes its load\n",
    "        fail_node(G, neighbors_dict, node_to_test)\n",
    "        \n",
    "        # Step 7: Run the cascade simulation\n",
    "        # This continues the cascade until no more nodes fail\n",
    "        # It returns the number of additional nodes that failed (cascading failures)\n",
    "        additional_failures = cascade_failure(G, neighbors_dict)\n",
    "        \n",
    "        # Step 8: Calculate total failures for this node\n",
    "        # Total = 1 (the initial failure) + all cascading failures\n",
    "        total_failures = 1 + additional_failures\n",
    "        \n",
    "        # Step 9: Store the result for this node\n",
    "        outcomes[node_to_test] = total_failures\n",
    "    \n",
    "    \n",
    "    # Find the worst node\n",
    "    sorted_outcomes = dict(sorted(outcomes.items(), key=lambda item: -item[1]))\n",
    "    worst_node, max_failures = list(sorted_outcomes.items())[0]\n",
    "    \n",
    "    return worst_node, max_failures, outcomes\n",
    "\n",
    "worst_node, max_failures, outcomes = find_worst_cascade_node()\n",
    "print(f\"Node {worst_node} causes the worst cascade with {max_failures} failures\")\n",
    "\n",
    "# BEGIN TESTS\n",
    "# @name(\"All Nodes Tested\")\n",
    "# @description(\"Check that all nodes in the network are tested\")\n",
    "test_worst_node, test_max_failures, test_outcomes = find_worst_cascade_node()\n",
    "def test_all_nodes_tested():\n",
    "    G = initialize_grid()\n",
    "    assert len(test_outcomes) == len(G.nodes()), \"Should test all nodes in the network\"\n",
    "    assert set(test_outcomes.keys()) == set(G.nodes()), \"Should have results for all nodes\"\n",
    "test_all_nodes_tested()\n",
    "\n",
    "# @name(\"Worst Node Identification\")\n",
    "# @description(\"Check that worst node is correctly identified\")\n",
    "def test_worst_node_identification():\n",
    "    assert test_worst_node in test_outcomes, \"Worst node should be in outcomes\"\n",
    "    assert test_outcomes[test_worst_node] == test_max_failures, \"Worst node should have max failures\"\n",
    "    assert test_max_failures == max(test_outcomes.values()), \"Max failures should be the maximum value\"\n",
    "test_worst_node_identification()\n",
    "\n",
    "# @name(\"Failure Counts\")\n",
    "# @description(\"Check that all failure counts are non-negative\")\n",
    "def test_failure_counts():\n",
    "    assert all(v >= 0 for v in test_outcomes.values()), \"All failure counts should be non-negative\"\n",
    "    assert test_max_failures >= 0, \"Max failures should be non-negative\"\n",
    "test_failure_counts()\n",
    "\n",
    "# @name(\"Results Consistency\")\n",
    "# @description(\"Check that outcomes dictionary has correct structure\")\n",
    "def test_results_consistency():\n",
    "    assert isinstance(test_outcomes, dict), \"Outcomes should be a dictionary\"\n",
    "    assert all(isinstance(v, int) for v in test_outcomes.values()), \"All cascade counts should be integers\"\n",
    "test_results_consistency()\n",
    "# END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = dict(sorted(outcomes.items(), key=lambda item: -item[1]))\n",
    "\n",
    "print(list(sorted_dict.items())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean station leads to {np.mean(list(outcomes.values()))} crashes.\")\n",
    "print(f\"The median station leads to {np.median(list(outcomes.values()))} crashes.\")\n",
    "print(f\"The max station leads to {max(list(outcomes.values()))} crashes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}