{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75be9f4-4d59-4f01-899a-1604fdbf3d03",
   "metadata": {},
   "source": [
    "# Semester 3 Coding Portfolio Topic 1 Formative Part 1/2:\n",
    "# APIs and simple webscraping with requests and BeautifulSoup\n",
    "\n",
    "This notebook covers the following topics:\n",
    " - Using APIs\n",
    " - Parsin JSON\n",
    " - Using the BeautifulSoup module\n",
    "\n",
    "This notebook is expected to take around 5 hours to complete:\n",
    " - 2 hours for the formative part\n",
    " - 3 hours of self-study on the topics covered by this notebook\n",
    "\n",
    "<b> This is a formative notebook</b><br>\n",
    "Simply complete the given functions such that they pass the automated tests. This part is graded Pass/Fail; you must get 100% correct!\n",
    "You can submit your notebook through Canvas as often as you like. Make sure to start doing so early to insure that your code passes all tests!\n",
    "You may ask for help from fellow students and TAs on this section, and solutions might be provided later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Please enter your student number here\n",
    "STUDENT_NUMBER = 15281914\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f05bb5-09df-43ea-b68a-605de67c7098",
   "metadata": {},
   "source": [
    "This notebook provides a quick introduction to simple web scraping with Python, requests and beautifulsoup.\n",
    "\n",
    "We will start by a simple introduction to using APIs, and then we'll look at requests to parse a simple website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a16138",
   "metadata": {},
   "source": [
    "# Interacting with APIs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4666dfe",
   "metadata": {},
   "source": [
    "An API, or Application Programming Interface, allows different software applications to talk to each other, sharing data and functionalities easily. Developers use APIs to access features or data from other services, enabling more complex and feature-rich applications. Essentially, APIs serve as bridges between different software, making it possible for them to interact and share resources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed8a61",
   "metadata": {},
   "source": [
    "We're going to start with getting data from a simple API. It's easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c99aac",
   "metadata": {},
   "source": [
    "## 1. Using a simple API:  How's the weather?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad2f85",
   "metadata": {},
   "source": [
    "To fetch data from any API or website, we can use the requests package. The requests package abstracts the complexities of making requests behind simple API methods, allowing developers to send HTTP/1.1 requests with various methods like GET, POST, PUT, and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcb621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae78b8d",
   "metadata": {},
   "source": [
    "As an example, we will use OpenWeatherMap.\n",
    "\n",
    "#### API Documentation: _Read The Fine Manual! (RTFM)_\n",
    "Public APIs always come with documentation that describes how to use the API, and what data you can expect. \n",
    "\n",
    "To find the OpenWeatherMap API, you can go to:\n",
    "https://openweathermap.org/api\n",
    "\n",
    "\n",
    "#### Getting the current weather\n",
    "We will here use the current weather function, to get the current weather in Amsterdam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435acf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the result from the API:\n",
      "{\"coord\":{\"lon\":4.8897,\"lat\":52.374},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04d\"}],\"base\":\"stations\",\"main\":{\"temp\":280.67,\"feels_like\":276.68,\"temp_min\":280.29,\"temp_max\":281.48,\"pressure\":1014,\"humidity\":87,\"sea_level\":1014,\"grnd_level\":1014},\"visibility\":6000,\"wind\":{\"speed\":7.72,\"deg\":210},\"clouds\":{\"all\":100},\"dt\":1764252764,\"sys\":{\"type\":2,\"id\":2101578,\"country\":\"NL\",\"sunrise\":1764228127,\"sunset\":1764257667},\"timezone\":3600,\"id\":2759794,\"name\":\"Amsterdam\",\"cod\":200}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"de26752686c975de6a1c38a998f50fec\"\n",
    "city_name = \"Amsterdam\"\n",
    "base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "\n",
    "# Complete URL for the API call\n",
    "url = f\"{base_url}q={city_name}&appid={api_key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Here is the result from the API:\")\n",
    "    print(response.text)\n",
    "    json_string = response.text\n",
    "else:\n",
    "    print(\"Error: Unable to get data from OpenWeatherMap API! :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a19736",
   "metadata": {},
   "source": [
    "#### Huh, what is this strange text?\n",
    "As you can see, the result we get is in a particular text format. This format is called JSON (pronounced \"Jason\"), which is used by most APIs - both internal and public.\n",
    "\n",
    "JSON (JavaScript Object Notation) is a data interchange format that is easy for humans to read and write and easy for machines to parse and generate. It is primarily used to transmit data between a server and a web application, serving as an alternative to XML, and is widely used for representing structured data and exchanging information in web development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee828a",
   "metadata": {},
   "source": [
    "### Parsing JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3920595",
   "metadata": {},
   "source": [
    "Luckily, JSON is very easy to parse using Python. We may for instance turn it into a dict. We use the json library to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037a1332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Amsterdam-----------\n",
      "Temperature: 280.67K\n",
      "Humidity: 87%\n",
      "Weather: Clouds\n",
      "Description: overcast clouds\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = json.loads(json_string)\n",
    "\n",
    "# Now parsed_data is a Python dictionary containing the data from the JSON string\n",
    "main = data['main']\n",
    "weather = data['weather']\n",
    "print(f\"{city_name:-^30}\")\n",
    "print(f\"Temperature: {main['temp']}K\")\n",
    "print(f\"Humidity: {main['humidity']}%\")\n",
    "print(f\"Weather: {weather[0]['main']}\")\n",
    "print(f\"Description: {weather[0]['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a053bc4",
   "metadata": {},
   "source": [
    "#### Exercise 1: Your turn! Get the forecast!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33719005",
   "metadata": {},
   "source": [
    "Now your task is to get the \"5 day / 3 hour forecast data\" from the API, to figure out how the weather in Amsterdam will be in the coming days. Read the manual!\n",
    "\n",
    "The goal is to print the date in the following format: \n",
    "- On 2023-10-06 12:00:00 the temperature will be 15 C\n",
    "- On 2023-10-06 15:00:00 the temperature will be  4 C\n",
    "\n",
    "etc.\n",
    "\n",
    "There are two extra challenges here. \n",
    "First, the datetime is a timestamp (a float value representing the number of seconds since January 1, 1970, the Unix epoch), which you will need to convert to a readable date.\n",
    "\n",
    "Second, you will need to convert the temperature from Kelvin to Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84646d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some help: a function to convert timestamp to date-time string\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_timestamp(dt):\n",
    "    dt_object = datetime.utcfromtimestamp(dt)\n",
    "    formatted_date = dt_object.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return formatted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-18-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 2025-11-27 15:00:00 the temperature will be 7.6 C\n",
      "On 2025-11-27 18:00:00 the temperature will be 7.4 C\n",
      "On 2025-11-27 21:00:00 the temperature will be 7.7 C\n",
      "On 2025-11-28 00:00:00 the temperature will be 8.0 C\n",
      "On 2025-11-28 03:00:00 the temperature will be 7.7 C\n",
      "On 2025-11-28 06:00:00 the temperature will be 8.4 C\n",
      "On 2025-11-28 09:00:00 the temperature will be 9.7 C\n",
      "On 2025-11-28 12:00:00 the temperature will be 10.7 C\n",
      "On 2025-11-28 15:00:00 the temperature will be 10.2 C\n",
      "On 2025-11-28 18:00:00 the temperature will be 9.3 C\n",
      "On 2025-11-28 21:00:00 the temperature will be 10.6 C\n",
      "On 2025-11-29 00:00:00 the temperature will be 9.0 C\n",
      "On 2025-11-29 03:00:00 the temperature will be 8.2 C\n",
      "On 2025-11-29 06:00:00 the temperature will be 7.6 C\n",
      "On 2025-11-29 09:00:00 the temperature will be 7.2 C\n",
      "On 2025-11-29 12:00:00 the temperature will be 9.7 C\n",
      "On 2025-11-29 15:00:00 the temperature will be 9.1 C\n",
      "On 2025-11-29 18:00:00 the temperature will be 8.3 C\n",
      "On 2025-11-29 21:00:00 the temperature will be 8.3 C\n",
      "On 2025-11-30 00:00:00 the temperature will be 8.7 C\n",
      "On 2025-11-30 03:00:00 the temperature will be 9.2 C\n",
      "On 2025-11-30 06:00:00 the temperature will be 9.6 C\n",
      "On 2025-11-30 09:00:00 the temperature will be 8.5 C\n",
      "On 2025-11-30 12:00:00 the temperature will be 8.5 C\n",
      "On 2025-11-30 15:00:00 the temperature will be 7.6 C\n",
      "On 2025-11-30 18:00:00 the temperature will be 5.0 C\n",
      "On 2025-11-30 21:00:00 the temperature will be 5.0 C\n",
      "On 2025-12-01 00:00:00 the temperature will be 5.6 C\n",
      "On 2025-12-01 03:00:00 the temperature will be 5.8 C\n",
      "On 2025-12-01 06:00:00 the temperature will be 5.8 C\n",
      "On 2025-12-01 09:00:00 the temperature will be 4.7 C\n",
      "On 2025-12-01 12:00:00 the temperature will be 5.7 C\n",
      "On 2025-12-01 15:00:00 the temperature will be 5.3 C\n",
      "On 2025-12-01 18:00:00 the temperature will be 5.3 C\n",
      "On 2025-12-01 21:00:00 the temperature will be 5.9 C\n",
      "On 2025-12-02 00:00:00 the temperature will be 6.1 C\n",
      "On 2025-12-02 03:00:00 the temperature will be 6.4 C\n",
      "On 2025-12-02 06:00:00 the temperature will be 5.7 C\n",
      "On 2025-12-02 09:00:00 the temperature will be 6.4 C\n",
      "On 2025-12-02 12:00:00 the temperature will be 8.2 C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"de26752686c975de6a1c38a998f50fec\"\n",
    "city_name = \"Amsterdam\"\n",
    "base_url = \"http://api.openweathermap.org/data/2.5/forecast?\"\n",
    "\n",
    "# Complete URL for the API call\n",
    "url = f\"{base_url}q={city_name}&appid={api_key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "    \n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    j = response.json()\n",
    "    # print(j)\n",
    "    # As you can see the json contains a list of timestamps and temperatures\n",
    "    # Loop over the list, and for each entry, parse the timestamp (using the method above)\n",
    "    # and print the dates and the temperature (tip: Kelvin - 273.15 = Celsius)\n",
    "    # Also, save any of the sentences to sample_text\n",
    "\n",
    "    # Your solution here\n",
    "    sample_text = None\n",
    "    for forecast in j['list']:\n",
    "        # Get timestamp and temperature\n",
    "        dt = forecast['dt']\n",
    "        temp_kelvin = forecast['main']['temp']\n",
    "        \n",
    "        # Parse timestamp to readable date\n",
    "        date_string = parse_timestamp(dt)\n",
    "        \n",
    "        # Convert Kelvin to Celsius\n",
    "        temp_celsius = temp_kelvin - 273.15\n",
    "        \n",
    "        # Print the forecast\n",
    "        print(f\"On {date_string} the temperature will be {temp_celsius:.1f} C\")\n",
    "        \n",
    "        # Save the first sentence to sample_text\n",
    "        if sample_text is None:\n",
    "            sample_text = f\"On {date_string} the temperature will be {temp_celsius:.1f} C\"\n",
    "else:\n",
    "    print(\"Error: Unable to get data from OpenWeatherMap API! :(\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce3e73d",
   "metadata": {},
   "source": [
    "Now you have a sense of how to get data from a simple API!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e92aa0",
   "metadata": {},
   "source": [
    "## 2. Simple webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab9e8c",
   "metadata": {},
   "source": [
    "Let's start by using _requests_ on a normal website instead. It's quite similar! We here use it to fetch the CSS programme website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ce4731-4b1c-4d47-8778-c07ad1b5b08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the result:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<!doctype html>\n",
      "<html class=\"no-js\" lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"utf-8\"/>\n",
      "\n",
      "    <title>Bachelor's Computational Social Science - University of Amsterdam</title>\n",
      "            <link rel=\"canonical\" href=\"https://www.uva.nl/en/programmes/bachelors/computational-social-science/computational- ...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.uva.nl/en/programmes/bachelors/computational-social-science/computational-social-science.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Here is the result:\")\n",
    "    print(f\"{response.text[:300]} ...\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcc01b-e205-43bc-80be-76c25ef481fa",
   "metadata": {},
   "source": [
    "As you can see, the result is in HTML: the simple markup language that the internet is built on.\n",
    "\n",
    "To get data from HTML, we therefore need to parse the HTML to fetch the data that we are interested in. This is core to all scraping.\n",
    "\n",
    "We therefore need a way of parsing the HTML to get the data that we are interested in.\n",
    "\n",
    "This is where BeautifulSoup comes in!\n",
    "\n",
    "Beautifulsoup is a complex library for parsing HTML.\n",
    "\n",
    "Let's first install it and load it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab3cee4-234c-497c-bb38-538ce7b49bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "# Install the library if you do not already have it\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5b8c36-2633-4a11-8749-4b3bcea4b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the library\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2c1c4-6257-4dc1-b227-65fd787392eb",
   "metadata": {},
   "source": [
    "### Parsing a simple example website with beautifulsoup\n",
    "As you may know, HTML is hierarchically structured  - sometimes referred to as an HTML parse tree or the DOM tree. The DOM is a tree data structure that represents the hierarchical structure of an HTML document. Each node in the tree corresponds to an element (or \"tag\") in the HTML document, and the edges represent the nesting relationships between the elements. The root of the tree is typically the <html> tag, and it has child nodes representing the head and body of the HTML document, and those child nodes, in turn, have their own child nodes representing nested elements within them.\n",
    "\n",
    "For example, consider a simple HTML document:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e8e9ca-7ad7-4d4e-8553-d42a9ec17a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplehtml = '''<html>\n",
    "    <head>\n",
    "        <title>My Page</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1 class='mainheader'>Welcome to My Page</h1>\n",
    "        <p id='theparagraph'>This is a paragraph.</p>\n",
    "        <p class='paraclass'>This is a second paragraph.</p>\n",
    "        <div><p>This is a third paragraph, inside a div!</p></div>\n",
    "    </body>\n",
    "</html>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ccf05",
   "metadata": {},
   "source": [
    "Let's try parsing elements of this page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81cc74e2-cdb5-4987-a1ca-23d63a196374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This turns the website into a beautifulsoup object that we can then fetch elements from\n",
    "soup = BeautifulSoup(simplehtml, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757f302",
   "metadata": {},
   "source": [
    "There are many functions in BeautifulSoup, but we will focus on soup.select(), which uses a _CSS selector_ to select elements and data.\n",
    "\n",
    "This function uses a particular type of strings for selecting elements, and returns a list of all matching elements (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e0e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Page\n"
     ]
    }
   ],
   "source": [
    "# This means \"select all elements of type 'title'\"\n",
    "alltitles = soup.select('title')\n",
    "# We then pick the first one; since we know there is only one\n",
    "firsttitle = alltitles[0]\n",
    "# And we can then select the text inside it, by getting the attribute text:\n",
    "print(firsttitle.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bac8630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a paragraph.\n",
      "This is a second paragraph.\n",
      "This is a third paragraph, inside a div!\n"
     ]
    }
   ],
   "source": [
    "# This means \"select all elements of type 'p'\"\n",
    "paragraphs = soup.select('p')\n",
    "# We then loop over the paragraphs and print each one\n",
    "for paragraph in paragraphs:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c1a7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a second paragraph.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This means \"select all elements of type 'p' with class 'paraclass'\"\n",
    "# The dot signifies class names\n",
    "# We can then select the first element, and the text content, in the same line\n",
    "soup.select('p.paraclass')[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e88786e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a paragraph.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This means \"select all elements of type 'p' with id 'theparagraph'\"\n",
    "# The # signifies id.\n",
    "soup.select('p#theparagraph')[0].text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a665ce90",
   "metadata": {},
   "source": [
    "### Exercise 2: Parse a simple website\n",
    "\n",
    "Your task is to parse the following simple website using beautifulsoup, and extract a dataframe that has the products listed, with their name, description, and price in separate columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81fab1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how the website looks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <title>Simple Website Example</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>Welcome to Our Simple Website</h1>\n",
       "<p>This is a demonstration of a simple HTML website designed for parsing practice.</p>\n",
       "<h2>About Us</h2>\n",
       "<p>We are a team dedicated to learning web scraping with BeautifulSoup.</p>\n",
       "<h3>Contact Information</h3>\n",
       "<p>Email us at: <a href=\"mailto:info@example.com\">info@example.com</a></p>\n",
       "<h2>Our Products</h2>\n",
       "<table border=\"1\">\n",
       "    <tr>\n",
       "        <th>Product Name</th>\n",
       "        <th>Description</th>\n",
       "        <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Product 1</td>\n",
       "        <td>An essential item for beginners.</td>\n",
       "        <td>$19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Product 2</td>\n",
       "        <td>A must-have for advanced users.</td>\n",
       "        <td>$29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Product 3</td>\n",
       "        <td>Now with bacon-flavor!</td>\n",
       "        <td>$39.99</td>\n",
       "    </tr>\n",
       "</table>\n",
       "\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "website_html = '''<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Simple Website Example</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Welcome to Our Simple Website</h1>\n",
    "<p>This is a demonstration of a simple HTML website designed for parsing practice.</p>\n",
    "<h2>About Us</h2>\n",
    "<p>We are a team dedicated to learning web scraping with BeautifulSoup.</p>\n",
    "<h3>Contact Information</h3>\n",
    "<p>Email us at: <a href=\"mailto:info@example.com\">info@example.com</a></p>\n",
    "<h2>Our Products</h2>\n",
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>Product Name</th>\n",
    "        <th>Description</th>\n",
    "        <th>Price</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Product 1</td>\n",
    "        <td>An essential item for beginners.</td>\n",
    "        <td>$19.99</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Product 2</td>\n",
    "        <td>A must-have for advanced users.</td>\n",
    "        <td>$29.99</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Product 3</td>\n",
    "        <td>Now with bacon-flavor!</td>\n",
    "        <td>$39.99</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>'''\n",
    "print(\"This is how the website looks:\")\n",
    "display(HTML(website_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dddcb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<th>Product Name</th>, <th>Description</th>, <th>Price</th>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the HTML to get the table and extract header row\n",
    "soup = BeautifulSoup(website_html, 'html.parser')\n",
    "table = soup.select('table')[0]\n",
    "header_row = table.select('tr')[0]\n",
    "header_columns = header_row.select('th')\n",
    "\n",
    "# Print the header columns\n",
    "header_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-38-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product 1</td>\n",
       "      <td>An essential item for beginners.</td>\n",
       "      <td>$19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product 2</td>\n",
       "      <td>A must-have for advanced users.</td>\n",
       "      <td>$29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product 3</td>\n",
       "      <td>Now with bacon-flavor!</td>\n",
       "      <td>$39.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product Name                       Description   Price\n",
       "0    Product 1  An essential item for beginners.  $19.99\n",
       "1    Product 2   A must-have for advanced users.  $29.99\n",
       "2    Product 3            Now with bacon-flavor!  $39.99"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd \n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(website_html, 'html.parser')\n",
    "\n",
    "# Find the table containing products\n",
    "product_table = soup.select('table')[0]\n",
    "\n",
    "# Extract the rows in the table, skipping the header row\n",
    "rows = product_table.select('tr')[1:]\n",
    "\n",
    "# Extract the data for each row\n",
    "products = []\n",
    "for row in rows:\n",
    "    # Select all tds in the row\n",
    "    # and put the first one in variable called product_name,\n",
    "    # second in description, and third in price\n",
    "    \n",
    "    # Your solution here\n",
    "    tds = row.select('td')\n",
    "    product_name = tds[0].text\n",
    "    description = tds[1].text\n",
    "    price = tds[2].text\n",
    "\n",
    "    products.append([product_name, description, price])\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(products, columns=['Product Name', 'Description', 'Price'])\n",
    "\n",
    "\n",
    "# Dataframe that has the products\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
